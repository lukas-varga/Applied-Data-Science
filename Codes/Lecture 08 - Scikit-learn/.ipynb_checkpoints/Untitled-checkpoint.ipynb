{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "\n",
    "We will start off by loading our data from the **data** folder of this lecture.\n",
    "\n",
    "Next we print of the dataset, than we split our **features** into **X** and our **target** into **Y**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.    148.     72.    ...   0.627  50.      1.   ]\n",
      " [  1.     85.     66.    ...   0.351  31.      0.   ]\n",
      " [  8.    183.     64.    ...   0.672  32.      1.   ]\n",
      " ...\n",
      " [  5.    121.     72.    ...   0.245  30.      0.   ]\n",
      " [  1.    126.     60.    ...   0.349  47.      1.   ]\n",
      " [  1.     93.     70.    ...   0.315  23.      0.   ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#import requests\n",
    "dataset = np.loadtxt('./data/pima-indians-diabetes.data.csv', delimiter=\",\")\n",
    "print(dataset)# separate the data from the target attributes\n",
    "X = dataset[:,0:7]\n",
    "y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print our Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.    148.     72.    ...   0.     33.6     0.627]\n",
      " [  1.     85.     66.    ...   0.     26.6     0.351]\n",
      " [  8.    183.     64.    ...   0.     23.3     0.672]\n",
      " ...\n",
      " [  5.    121.     72.    ... 112.     26.2     0.245]\n",
      " [  1.    126.     60.    ...   0.     30.1     0.349]\n",
      " [  1.     93.     70.    ...   0.     30.4     0.315]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print our Target Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0.\n",
      " 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0.\n",
      " 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
      " 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
      " 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0.\n",
      " 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1.\n",
      " 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0.\n",
      " 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
      " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1.\n",
      " 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1.\n",
      " 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Normalisation and standardization\n",
    "\n",
    "The majority of models are highly sensitive to data scaling. Prior to running an algorithm, Nomalisation and standardisatoin should be performed.\n",
    "\n",
    "**Normalization** involves replacing nominal features, so that each of them would be in a range from 0 to 1.\n",
    "\n",
    "**standardization** involves data preproccessing, after which each feature has and average 0 and 1 dispersion(all data does not follow normal distribution).\n",
    "\n",
    "Scikit-learn provides libraries for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "#normalize the data attributes\n",
    "normalized_X = preprocessing.normalize(X)\n",
    "\n",
    "#standardizes the data attributes\n",
    "standardized_X = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03494617 0.86200564 0.41935409 ... 0.         0.19569858 0.00365188]\n",
      " [0.00872683 0.74178025 0.57597054 ... 0.         0.23213358 0.00306312]\n",
      " [0.04093566 0.93640332 0.32748532 ... 0.         0.11922512 0.0034386 ]\n",
      " ...\n",
      " [0.02727338 0.66001582 0.39273669 ... 0.61092373 0.14291252 0.0013364 ]\n",
      " [0.0070043  0.8825414  0.42025781 ... 0.         0.21082934 0.0024445 ]\n",
      " [0.00804902 0.74855891 0.56343144 ... 0.         0.24469022 0.00253544]]\n"
     ]
    }
   ],
   "source": [
    "print(normalized_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.63994726  0.84832379  0.14964075 ... -0.69289057  0.20401277\n",
      "   0.46849198]\n",
      " [-0.84488505 -1.12339636 -0.16054575 ... -0.69289057 -0.68442195\n",
      "  -0.36506078]\n",
      " [ 1.23388019  1.94372388 -0.26394125 ... -0.69289057 -1.10325546\n",
      "   0.60439732]\n",
      " ...\n",
      " [ 0.3429808   0.00330087  0.14964075 ...  0.27959377 -0.73518964\n",
      "  -0.68519336]\n",
      " [-0.84488505  0.1597866  -0.47073225 ... -0.69289057 -0.24020459\n",
      "  -0.37110101]\n",
      " [-0.84488505 -0.8730192   0.04624525 ... -0.69289057 -0.20212881\n",
      "  -0.47378505]]\n"
     ]
    }
   ],
   "source": [
    "print(standardized_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "The most import thing in solving a task is the ability to properly choose or even create **features**, also called **Feature Selection**\n",
    "\n",
    "Good features are more import than good methods.\n",
    "\n",
    "There are many ready-made algorithms for **Feature Selection**. Tree algorithms allow to compute the informativeness of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12679597 0.272837   0.11836486 0.08862803 0.08419173 0.16895893\n",
      " 0.14022348]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model=ExtraTreesClassifier()\n",
    "model.fit(X,y)\n",
    "#display the relative importance of each attribute\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature_selection Module\n",
    "\n",
    "The classes in this module can be used for feature selection/dimensionality reduction on sample sets, either to improve estimators accuracy or to boost their performance on very high-dimensional data\n",
    "\n",
    "### Recursive Feature Elimination (RFE)\n",
    "\n",
    "Given an external estimator that assigns weights to feature(e.g. for example the coeffients of a linear model), recursive feature elimination is to select by recursively considering smaller and smaller sets of features.\n",
    "\n",
    "First the estimator is trained on the intial set of features and the importance of each feature is obtained either through a ``coef_`` attribute or through a ``feature_importances_`` attribute.\n",
    "\n",
    "Then the least import features are pruned from the current set of features\n",
    "\n",
    "That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 5 4 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/istvan/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression\n",
    "\n",
    "#create the RFE and select 3 attributes\n",
    "rfe =RFE(model,3)\n",
    "rfe=rfe.fit(X,y)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** There is a warning message regarding our data, in this instance our data has not been normalised or standardized. Lets try the same code with our data being normalised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 3 5 4 1 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "\n",
    "#create the RFE and select 3 attributes\n",
    "rfe =RFE(model,3)\n",
    "rfe=rfe.fit(standardized_X,y)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Often used to solve tasks of classification(binary), but multi-class classification is also allowed (**one-versus-rest**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.00      0.00       500\n",
      "         1.0       0.35      1.00      0.52       268\n",
      "\n",
      "    accuracy                           0.35       768\n",
      "   macro avg       0.67      0.50      0.26       768\n",
      "weighted avg       0.77      0.35      0.18       768\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(standardized_X, y)\n",
    "\n",
    "expected = y\n",
    "predicted=model.predict(X)\n",
    "print(metrics.classification_report(expected,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.92      0.84       500\n",
      "         1.0       0.76      0.48      0.59       268\n",
      "\n",
      "    accuracy                           0.77       768\n",
      "   macro avg       0.76      0.70      0.71       768\n",
      "weighted avg       0.76      0.77      0.75       768\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "model=SVC()\n",
    "model.fit(X,y)\n",
    "\n",
    "expect=y\n",
    "predicted=model.predict(X)\n",
    "print(metrics.classification_report(expected,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.86      0.83       500\n",
      "         1.0       0.69      0.60      0.64       268\n",
      "\n",
      "    accuracy                           0.77       768\n",
      "   macro avg       0.75      0.73      0.73       768\n",
      "weighted avg       0.76      0.77      0.76       768\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "model=GaussianNB()\n",
    "model.fit(X,y)\n",
    "\n",
    "expect=y\n",
    "predicted=model.predict(X)\n",
    "print(metrics.classification_report(expected,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.90      0.86       500\n",
      "         1.0       0.77      0.63      0.69       268\n",
      "\n",
      "    accuracy                           0.80       768\n",
      "   macro avg       0.79      0.77      0.78       768\n",
      "weighted avg       0.80      0.80      0.80       768\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model=KNeighborsClassifier()\n",
    "model.fit(X,y)\n",
    "\n",
    "expect=y\n",
    "predicted=model.predict(X)\n",
    "print(metrics.classification_report(expected,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       500\n",
      "         1.0       1.00      1.00      1.00       268\n",
      "\n",
      "    accuracy                           1.00       768\n",
      "   macro avg       1.00      1.00      1.00       768\n",
      "weighted avg       1.00      1.00      1.00       768\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model=DecisionTreeClassifier()\n",
    "model.fit(X,y)\n",
    "\n",
    "expect=y\n",
    "predicted=model.predict(X)\n",
    "print(metrics.classification_report(expected,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
