{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTH - Twitter Data Analysis\n",
    "## Lukáš Varga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "#my credentials\n",
    "credentials = {}\n",
    "credentials[\"CONSUMER_KEY\"] = \"al3O7cOIE9XNk13NQjRnDhKYk\"\n",
    "credentials[\"CONSUMER_SECRET\"] = \"mdWuXncUkVNd9zqg4CFH1rX4Nr0KZ3PqNi2s8E10vbvEFsNtDL\"\n",
    "credentials[\"BEARER_TOKEN\"] = \"AAAAAAAAAAAAAAAAAAAAAO8yKwEAAAAAz3eP0eIcjI1ZFPXb72mV7Z5JSHQ%3DVkCRmKYKE6SBapkSWXUmWmC5rQqWmQzfFPxmxhuNrGgF6mmz2S\"\n",
    "credentials[\"ACCESS_TOKEN\"] = \"1108440414795849735-eej2D9NxAI1oIVmsGADjrf9yEpRUvN\"\n",
    "credentials[\"ACCESS_TOKEN_SECRET\"] = \"S3q0osEtfz6Hwn5wmdyQXsMwbTkU9AdCOpxqGdx7iMfkX\"\n",
    "\n",
    "#save to json\n",
    "with open(\"twitter_credentials.json\", \"w\") as file:\n",
    "    json.dump(credentials, file)\n",
    "    \n",
    "print(\"JSON file with credentials was created!\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import json #JSON credentials\n",
    "import csv #CSV results\n",
    "import tweepy as tw #twitter API\n",
    "import pandas as pd #dataframes\n",
    "from textblob import TextBlob #sentiment\n",
    "import re #regex\n",
    "import matplotlib.pyplot as plt #graphs\n",
    "import sys #max integer\n",
    "\n",
    "#asking user about event\n",
    "EVENT = input(\"Please enter the event: #\")\n",
    "EVENT = EVENT.lower()\n",
    "SEARCH_EVENT = \"#\" + str(EVENT) + \"-filter:retweets\"\n",
    "\n",
    "#parameters for filtering\n",
    "#SINCE_DATE = \"2021-01-01\"\n",
    "#ITEM_NUM = 100\n",
    "SINCE_DATE = input(\"Enter the oldest possible date of tweets. Use format \\\"YYYY-MM-DD\\\": \")\n",
    "ITEM_NUM_STR = input(\"Enter the maximum number of tweets (Empty for no limit): \")\n",
    "\n",
    "ITEM_NUM = sys.maxsize\n",
    "if(len(ITEM_NUM_STR) != 0):\n",
    "    ITEM_NUM = int(ITEM_NUM_STR)\n",
    "print(\"Loading data set...\")\n",
    "\n",
    "#load credentials\n",
    "with open(\"twitter_credentials.json\", \"r\") as file:\n",
    "    creds = json.load(file)\n",
    "\n",
    "#set authentification\n",
    "auth = tw.OAuthHandler(creds[\"CONSUMER_KEY\"], creds[\"CONSUMER_SECRET\"])\n",
    "auth.set_access_token(creds[\"ACCESS_TOKEN\"], creds[\"ACCESS_TOKEN_SECRET\"])\n",
    "api = tw.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "\n",
    "#get data set\n",
    "\n",
    "tweets = tw.Cursor(api.search,\n",
    "                   q = SEARCH_EVENT,\n",
    "                   lang = \"en\",\n",
    "                   since = SINCE_DATE).items(ITEM_NUM)\n",
    "\n",
    "tweets_dataset=[]\n",
    "for tweet in tweets:\n",
    "    hashtags = tweet.entities.get(\"hashtags\")\n",
    "    tags=[]\n",
    "    for hashtag in hashtags:\n",
    "        tag = hashtag['text'].lower()\n",
    "        tags.append(tag)\n",
    "    tweets_dataset.append([tweet.author.screen_name,tweet.author.name,tweet.text,tags])\n",
    "    \n",
    "df_tweets = pd.DataFrame(tweets_dataset,columns=[\"user\",\"real_name\",\"text\",\"hashtags\"])\n",
    "\n",
    "size = len(df_tweets.index)\n",
    "#pd.set_option(\"display.max_rows\",size)\n",
    "pd.reset_option(\"display.max_rows\")\n",
    "display(df_tweets)\n",
    "\n",
    "print(\"Data set has been loaded!\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Derive the sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SENTIMENT\n",
    "print(\"Computing sentiment...\")\n",
    "\n",
    "#delete all URLs and unallowed chars using REGEX\n",
    "def remove_url(text):\n",
    "    return \" \".join(re.sub(\"(\\w+:\\/\\/\\w+)|([^0-9A-Za-z\\t ])\", \"\", text).split())\n",
    "\n",
    "texts = df_tweets[\"text\"]\n",
    "clear_tweets = []\n",
    "for text in texts:\n",
    "    clear_tweets.append(remove_url(text))\n",
    "\n",
    "#creting obj using TextBlob\n",
    "sentim_obj = []\n",
    "for text in clear_tweets:\n",
    "    sentim_obj.append(TextBlob(text))\n",
    "\n",
    "#extracting polarity  \n",
    "sentim_values = []\n",
    "for tweet in sentim_obj:\n",
    "    sentim_values.append([str(tweet),tweet.sentiment.polarity])\n",
    "\n",
    "#creating dataframe with results\n",
    "sentiment_df = pd.DataFrame(sentim_values, columns=[\"clear_tweet\",\"sentiment\"])\n",
    "\n",
    "#histogram (w/o zero values for better visualisation)\n",
    "clear_sentiment_df = sentiment_df[sentiment_df.sentiment!=0]\n",
    "x=clear_sentiment_df[\"sentiment\"]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"Sentiment (Omitting 0 values)\")\n",
    "ax.set_ylabel(\"Counts\")\n",
    "ax.set_title(\"Histogram of sentiments in #\"+EVENT)\n",
    "ax.hist(x,bins=[-1, -0.75, -0.5, -0.25, 0, 0.25, 0.5, 0.75, 1])\n",
    "plt.grid(True)\n",
    "\n",
    "#display and save histogram\n",
    "plt.savefig(\"01_sentiment_vis.png\")\n",
    "print(\"PNG file of sentiments was created!\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#display and save dataframe\n",
    "sentiment_df.to_csv(\"01_sentiment_res.csv\",index=False,sep=\";\")\n",
    "print(\"CSV file of sentiments was created!\")\n",
    "\n",
    "size = len(sentiment_df.index)\n",
    "pd.set_option(\"display.max_rows\",size)\n",
    "#pd.reset_option(\"display.max_rows\")\n",
    "display(sentiment_df)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Top 10 hashtags and users "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TOP10 hashtags\n",
    "print(\"Looking for Top 10 hashtags...\")\n",
    "\n",
    "hashtags_dict={}\n",
    "\n",
    "for i in range(len(df_tweets)):\n",
    "    hashtahgs = df_tweets.loc[i,\"hashtags\"]\n",
    "    for tag in hashtahgs:\n",
    "        if tag in hashtags_dict.keys():\n",
    "            hashtags_dict[tag] += 1\n",
    "        else:\n",
    "            hashtags_dict[tag] = 1\n",
    "\n",
    "sorted_hashtags_dict = sorted(hashtags_dict, key=hashtags_dict.get, reverse=True)\n",
    "top_hashtags_dict={}\n",
    "i=0\n",
    "\n",
    "for hashtag in sorted_hashtags_dict:\n",
    "    if(i==10):\n",
    "        break\n",
    "    top_hashtags_dict[hashtag] = hashtags_dict[hashtag]\n",
    "    i+=1\n",
    "\n",
    "    \n",
    "res_hashtags = []\n",
    "for hashtag in top_hashtags_dict:\n",
    "    res_hashtags.append([hashtag,top_hashtags_dict[hashtag]])\n",
    "    \n",
    "df_hashtags = pd.DataFrame(res_hashtags, columns=[\"#hashtag\",\"occurrence\"])\n",
    "df_hashtags.to_csv('02_top10_hashtags.csv',index=False,sep=\";\")\n",
    "print(\"CSV file of Top 10 hashtags was created!\")\n",
    "\n",
    "size = len(df_hashtags.index)\n",
    "pd.set_option(\"display.max_rows\",size)\n",
    "#pd.reset_option(\"display.max_rows\")\n",
    "display(df_hashtags)\n",
    "\n",
    "\n",
    "#TOP10 users\n",
    "print(\"Looking for Top 10 users...\")\n",
    "\n",
    "users_dict={} #user->counts\n",
    "names_dict={} #user->name\n",
    "users = []\n",
    "\n",
    "for i in range(len(df_tweets)):\n",
    "    user = df_tweets.loc[i,\"user\"]# @user\n",
    "    name = df_tweets.loc[i,\"real_name\"]# alias\n",
    "    if user in users_dict.keys():\n",
    "        users_dict[user] += 1\n",
    "    else:\n",
    "        users_dict[user] = 1\n",
    "        names_dict[user] = name\n",
    "     \n",
    "    \n",
    "sorted_users_dict = sorted(users_dict, key=users_dict.get, reverse=True)\n",
    "top_users_dict={}\n",
    "top_names_dict={}\n",
    "i=0\n",
    "\n",
    "for user in sorted_users_dict:\n",
    "    if(i==10):\n",
    "        break\n",
    "    top_users_dict[user] = users_dict[user]\n",
    "    top_names_dict[user] = names_dict[user]\n",
    "    i+=1\n",
    "\n",
    "res_users = []\n",
    "for user in top_users_dict:\n",
    "    res_users.append([user,top_names_dict[user],top_users_dict[user]])\n",
    "    \n",
    "df_users = pd.DataFrame(res_users, columns=[\"@user\",\"real_name\",\"occurrence\"])\n",
    "\n",
    "df_users.to_csv('02_top10_users.csv',index=False,sep=\";\")\n",
    "print(\"CSV file of Top 10 users was created!\")\n",
    "\n",
    "size = len(df_users.index)\n",
    "pd.set_option(\"display.max_rows\",size)\n",
    "#pd.reset_option(\"display.max_rows\")\n",
    "display(df_users)\n",
    "\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Followers of a given user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOLLOWERS\n",
    "print(\"Displaying usernames in data set...\")\n",
    "\n",
    "#displaying users to choose\n",
    "users=[]\n",
    "for i in range(len(df_tweets)):\n",
    "    users.append(df_tweets.loc[i,\"user\"])\n",
    "    \n",
    "df_users = pd.DataFrame(users, columns=[\"dataset_@user\"])\n",
    "df_users.drop_duplicates(subset=[\"dataset_@user\"], keep=\"first\", inplace=True)\n",
    "df_users = df_users.reset_index(drop=True)\n",
    "    \n",
    "size = len(df_users.index)\n",
    "pd.set_option(\"display.max_rows\",size)\n",
    "#pd.reset_option(\"display.max_rows\")\n",
    "display(df_users)\n",
    "\n",
    "USER_NAME = input(\"Please provide a username to examine his followers: \")\n",
    "USER_COUNT_STR = input(\"Please provide a max number of results (Empty for no limit): \")\n",
    "\n",
    "USER_COUNT = sys.maxsize\n",
    "if(len(USER_COUNT_STR) != 0):\n",
    "    USER_COUNT = int(USER_COUNT_STR)\n",
    "print(\"Looking for followers...\")\n",
    "\n",
    "users = tw.Cursor(api.followers,\n",
    "                  screen_name = USER_NAME).items(USER_COUNT)\n",
    "\n",
    "followers = []\n",
    "for user in users:\n",
    "    followers.append([user.screen_name, user.name])\n",
    "\n",
    "df_followers = pd.DataFrame(followers, columns=[\"@user\",\"real_name\"])\n",
    "\n",
    "df_followers.to_csv('03_followers.csv',index=False,sep=\";\")\n",
    "csv = f\"CSV file of followers of the user @{USER_NAME} was created!\"\n",
    "print(csv)\n",
    "    \n",
    "size = len(df_followers.index)\n",
    "pd.set_option(\"display.max_rows\",size)\n",
    "display(df_followers)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Tweets and profiles of all followers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TWEETS\n",
    "print(\"Displaying usernames in data set...\")\n",
    "\n",
    "#displaying users to choose\n",
    "users=[]\n",
    "for i in range(len(df_tweets)):\n",
    "    users.append(df_tweets.loc[i,\"user\"])\n",
    "    \n",
    "df_users = pd.DataFrame(users, columns=[\"dataset_@user\"])\n",
    "df_users.drop_duplicates(subset=[\"dataset_@user\"], keep=\"first\", inplace=True)\n",
    "df_users = df_users.reset_index(drop=True)\n",
    "    \n",
    "size = len(df_users.index)\n",
    "pd.set_option(\"display.max_rows\",size)\n",
    "#pd.reset_option(\"display.max_rows\",size)\n",
    "display(df_users)\n",
    "\n",
    "USER_NAME = input(\"Please provide a username to get his tweets and profiles of followers: \")\n",
    "\n",
    "TWEET_COUNT_STR = input(\"Please provide a max number of tweets (Empty for no limit): \")\n",
    "TWEET_COUNT = sys.maxsize\n",
    "if(len(TWEET_COUNT_STR) != 0):\n",
    "    TWEET_COUNT = int(TWEET_COUNT_STR)\n",
    "    \n",
    "PROFILE_COUNT_STR = input(\"Please provide a max number of profiles (Empty for no limit): \")\n",
    "PROFILE_COUNT = sys.maxsize\n",
    "if(len(PROFILE_COUNT_STR) != 0):\n",
    "    PROFILE_COUNT = int(PROFILE_COUNT_STR)\n",
    "\n",
    "\n",
    "print(\"Looking for tweets of given user...\")\n",
    "    \n",
    "tweets = tw.Cursor(api.user_timeline,\n",
    "                  id = USER_NAME).items(TWEET_COUNT)\n",
    "\n",
    "tweets_arr = []\n",
    "for tweet in tweets:\n",
    "    tweets_arr.append(tweet.text)\n",
    "\n",
    "df_texts = pd.DataFrame(tweets_arr, columns=[\"text\"])\n",
    "\n",
    "df_texts.to_csv('04_tweets.csv',index=False,sep=\";\")\n",
    "csv = f\"CSV file of tweets of the user @{USER_NAME} was created!\"\n",
    "print(csv)\n",
    "    \n",
    "size = len(df_texts.index)\n",
    "pd.set_option(\"display.max_rows\",size)\n",
    "#pd.reset_option(\"display.max_rows\")\n",
    "display(df_texts)\n",
    "\n",
    "print(\"Done!\")\n",
    "\n",
    "#PROFILES\n",
    "print(\"Looking for profiles of given user...\")\n",
    "    \n",
    "users = tw.Cursor(api.followers,\n",
    "                  screen_name = USER_NAME).items(PROFILE_COUNT)\n",
    "\n",
    "profiles_arr = []\n",
    "for user in users:\n",
    "    profile = f\"https://twitter.com/{user.screen_name}\"\n",
    "    profiles_arr.append([user.screen_name, user.name, profile])\n",
    "\n",
    "df_profiles = pd.DataFrame(profiles_arr, columns=[\"user\",\"real_name\",\"profile\"])\n",
    "\n",
    "df_profiles.to_csv('04_profiles.csv',index=False,sep=\";\")\n",
    "csv = f\"CSV file of profiles of the user @{USER_NAME} was created!\"\n",
    "print(csv)\n",
    "    \n",
    "size = len(df_profiles.index)\n",
    "pd.set_option(\"display.max_rows\",size)\n",
    "#pd.reset_option(\"display_max_rows\")\n",
    "display(df_profiles)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
